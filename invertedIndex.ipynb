{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "with open('Dataset\\stoplist.txt') as file:\n",
    "    stoplist = [line.lower().strip() for line in file]\n",
    "stoplist += ['.','¿','?','-','anillo',',',':',';','(',')','«', '»']\n",
    "\n",
    "def palabras_raiz(texto):\n",
    "    with open(texto, encoding=\"utf-8\") as file:\n",
    "        libro = ''\n",
    "        for line in file:\n",
    "            libro += line.lower()\n",
    "    libro_palabras = nltk.word_tokenize(libro)\n",
    "\n",
    "    libro_palabras_limpias = libro_palabras[:]\n",
    "    for token in libro_palabras:\n",
    "        if token in stoplist:\n",
    "            libro_palabras_limpias.remove(token)\n",
    "\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    libro_palabras_raiz = []\n",
    "    for w in libro_palabras_limpias:\n",
    "        libro_palabras_raiz.append(stemmer.stem(w))\n",
    "    return libro_palabras_raiz\n",
    "\n",
    "libro1_palabras_raiz = palabras_raiz('Dataset\\libro1.txt')\n",
    "libro2_palabras_raiz = palabras_raiz('Dataset\\libro2.txt')\n",
    "libro3_palabras_raiz = palabras_raiz('Dataset\\libro3.txt')\n",
    "libro4_palabras_raiz = palabras_raiz('Dataset\\libro4.txt')\n",
    "libro5_palabras_raiz = palabras_raiz('Dataset\\libro5.txt')\n",
    "libro6_palabras_raiz = palabras_raiz('Dataset\\libro6.txt')\n",
    "\n",
    "from collections import Counter\n",
    "libro_count_palabras = libro1_palabras_raiz + libro2_palabras_raiz + libro3_palabras_raiz + libro4_palabras_raiz + libro5_palabras_raiz + libro6_palabras_raiz\n",
    "counter=Counter(libro_count_palabras)\n",
    "most_common_palabras = sorted([i[0] for i in counter.most_common(500)])\n",
    "\n",
    "index = {i: [] for i in most_common_palabras} \n",
    "\n",
    "for i in index.keys():\n",
    "    if i in libro1_palabras_raiz:\n",
    "        index[i].append(1)\n",
    "    if i in libro2_palabras_raiz:\n",
    "        index[i].append(2)\n",
    "    if i in libro3_palabras_raiz:\n",
    "        index[i].append(3)\n",
    "    if i in libro4_palabras_raiz:\n",
    "        index[i].append(4)\n",
    "    if i in libro5_palabras_raiz:\n",
    "        index[i].append(5)\n",
    "    if i in libro6_palabras_raiz:\n",
    "        index[i].append(6)\n",
    "\n",
    "with open('invertIndex.txt', 'w') as f:\n",
    "    for i in index.keys():\n",
    "        f.write(str(i) + ' : ')\n",
    "        for j in index[i]:\n",
    "            f.write(str(j) + ' ')\n",
    "        f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InvertIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((Frodor AND Gandalf) OR Gondor) aparecen en los libros:  [1, 2, 3, 5, 6]\n",
      "((Frodor OR Gandalf) ANDNOT Gondor) aparecen en los libros:  [1, 4]\n",
      "((Frodor OR Gandalf) AND Gondor) aparecen en los libros:  [2, 3, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "class InvertIndex:\n",
    "    def __init__(self): \n",
    "            self.index = index\n",
    "\n",
    "    def L(self, key):\n",
    "        stemmer = SnowballStemmer('spanish')\n",
    "        key = stemmer.stem(key.lower())\n",
    "        if key not in self.index:\n",
    "            return []\n",
    "        else:\n",
    "            return self.index[key]\n",
    "    \n",
    "    def AND(self, L1, L2):\n",
    "        return self.intersect(L1, L2)\n",
    "\n",
    "    def OR(self, L1, L2):\n",
    "        return self.union(L1, L2)\n",
    "\n",
    "    def ANDNOT(self, L1, L2):\n",
    "        return self.difference(L1, L2)\n",
    "    \n",
    "    def intersect(self, L1, L2):\n",
    "        result = []\n",
    "        p1 = 0\n",
    "        p2 = 0\n",
    "        while p1<len(L1) and p2<len(L2):\n",
    "            if L1[p1] == L2[p2]:\n",
    "                result.append(L1[p1])\n",
    "                p1+=1\n",
    "                p2+=1\n",
    "            elif L1[p1] < L2[p2]:\n",
    "                p1+=1\n",
    "            else:\n",
    "                p2+=1\n",
    "        return result\n",
    "\n",
    "    def union(self, L1, L2):\n",
    "        result = []\n",
    "        for i in L1:\n",
    "            if i not in result:\n",
    "                result.append(i)\n",
    "        for i in L2:\n",
    "            if i not in result:\n",
    "                result.append(i)\n",
    "        return result\n",
    "    \n",
    "    def difference(self, L1, L2):\n",
    "        result = []\n",
    "        for i in L1:\n",
    "            if i not in result:\n",
    "                result.append(i)\n",
    "        for i in L2:\n",
    "            if i in result:\n",
    "                result.remove(i)\n",
    "        return result\n",
    "\n",
    "retrieve = InvertIndex()\n",
    "consulta1 = retrieve.OR(retrieve.AND(retrieve.L(\"Frodo\"), retrieve.L(\"Gandalf\")), retrieve.L(\"Gondor\"))\n",
    "consulta2 = retrieve.ANDNOT(retrieve.OR(retrieve.L(\"Frodo\"), retrieve.L(\"Gandalf\")), retrieve.L(\"Gondor\"))\n",
    "consulta3 = retrieve.AND(retrieve.OR(retrieve.L(\"Frodo\"), retrieve.L(\"Gandalf\")), retrieve.L(\"Gondor\"))\n",
    "print(\"((Frodor AND Gandalf) OR Gondor) aparecen en los libros: \", consulta1)\n",
    "print(\"((Frodor OR Gandalf) ANDNOT Gondor) aparecen en los libros: \", consulta2)\n",
    "print(\"((Frodor OR Gandalf) AND Gondor) aparecen en los libros: \", consulta3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
